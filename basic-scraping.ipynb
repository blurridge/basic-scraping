{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Making your first HTTP request**\n",
    "HTTP requests allow you to interact with web servers, retrieve information from websites, or send data to web APIs.\n",
    "\n",
    "Weâ€™ll send a GET request to https://webscraper.io/test-sites/e-commerce/allinone and print various components of the response object, such as the status code, headers, and the content of the webpage. This will help us understand how to access and manipulate the data received from a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "TEST_SITE = \"https://webscraper.io/test-sites/e-commerce/allinone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to https://webscraper.io/test-sites/e-commerce/allinone\n",
    "response = requests.get(TEST_SITE)\n",
    "\n",
    "# Print all the contents of the response object\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Headers:\", response.headers)\n",
    "print(\"Cookies:\", response.cookies)\n",
    "print(\"Encoding:\", response.encoding)\n",
    "print(\"Elapsed Time:\", response.elapsed)\n",
    "print(\"URL:\", response.url)\n",
    "print(\"Request:\", response.request)\n",
    "print(\"History:\", response.history)\n",
    "print(\"Text (HTML content):\", response.text)  # If the response is HTML or text\n",
    "print(\"Content (bytes):\", response.content)   # If the response contains binary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parsing HTML with BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding elements by tag\n",
    "first_h1 = soup.find('h1')\n",
    "first_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding elements by id\n",
    "soup.find(id='navbar-top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all elements with class card-text\n",
    "card_texts = soup.find_all('p', class_='card-text')\n",
    "card_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for card in card_texts:\n",
    "    print(card.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Challenge**\n",
    "\n",
    "I will give you 5 minutes to finish this code snippet. I want to get all product names in blue and print them. There is a code snippet here and just fill it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://webscraper.io/test-sites/e-commerce/allinone\")\n",
    "soup = BeautifulSoup(response.text)\n",
    "product_names = soup.find_all('____', class_=\"____\")\n",
    "for ________ in product_names:\n",
    "    title = product_name.get(\"________\")\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **What if I want to store all data related to a product into an object?**\n",
    "\n",
    "You can definitely do that. We can get the item's name, price, description and store it in a list of objects which we can refer to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "response = requests.get(\"https://webscraper.io/test-sites/e-commerce/allinone\")\n",
    "soup = BeautifulSoup(response.text)\n",
    "cards = soup.find_all('div', class_=\"col-md-4 col-xl-4 col-lg-4\")\n",
    "products = []\n",
    "for card in cards:\n",
    "    name = card.find('a', class_='title').get('title')\n",
    "    description = card.find('p', class_=\"description\").text\n",
    "    price = card.find('h4', class_='price').text\n",
    "    rating = card.find('p', attrs={'data-rating': True}).get('data-rating')\n",
    "    product = {\n",
    "        \"product_name\": name,\n",
    "        \"product_description\": description,\n",
    "        \"product_price\": price,\n",
    "        \"product_rating\": rating\n",
    "    }\n",
    "    products.append(product)\n",
    "\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(products)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(\"products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Indeed Scraping with BS4 Fail Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://ph.indeed.com/jobs?q=software+engineer&l=Cebu+City,+Cebu&from=searchOnHP&vjk=9c965703860005b0\")\n",
    "soup = BeautifulSoup(response.text)\n",
    "print(soup.prettify())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
